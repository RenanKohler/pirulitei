/* 
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * OpenAPI spec version: 2.0.0
 * 
 * Generated by: https://github.com/swagger-api/swagger-codegen.git
 */
using System;
using System.Linq;
using System.IO;
using System.Text;
using System.Text.RegularExpressions;
using System.Collections;
using System.Collections.Generic;
using System.Collections.ObjectModel;
using System.Runtime.Serialization;
using Newtonsoft.Json;
using Newtonsoft.Json.Converters;
using System.ComponentModel.DataAnnotations;
using SwaggerDateConverter = IO.Swagger.Client.SwaggerDateConverter;
namespace IO.Swagger.Model
{
    /// <summary>
    /// The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/legacy-fine-tuning/hyperparameters) for more details.
    /// </summary>
    [DataContract]
        public partial class FineTuneHyperparams :  IEquatable<FineTuneHyperparams>, IValidatableObject
    {
        /// <summary>
        /// Initializes a new instance of the <see cref="FineTuneHyperparams" /> class.
        /// </summary>
        /// <param name="batchSize">The batch size to use for training. The batch size is the number of training examples used to train a single forward and backward pass.  (required).</param>
        /// <param name="classificationNClasses">The number of classes to use for computing classification metrics. .</param>
        /// <param name="classificationPositiveClass">The positive class to use for computing classification metrics. .</param>
        /// <param name="computeClassificationMetrics">The classification metrics to compute using the validation dataset at the end of every epoch. .</param>
        /// <param name="learningRateMultiplier">The learning rate multiplier to use for training.  (required).</param>
        /// <param name="nEpochs">The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.  (required).</param>
        /// <param name="promptLossWeight">The weight to use for loss on the prompt tokens.  (required).</param>
        public FineTuneHyperparams(int? batchSize = default(int?), int? classificationNClasses = default(int?), string classificationPositiveClass = default(string), bool? computeClassificationMetrics = default(bool?), decimal? learningRateMultiplier = default(decimal?), int? nEpochs = default(int?), decimal? promptLossWeight = default(decimal?))
        {
            // to ensure "batchSize" is required (not null)
            if (batchSize == null)
            {
                throw new InvalidDataException("batchSize is a required property for FineTuneHyperparams and cannot be null");
            }
            else
            {
                this.BatchSize = batchSize;
            }
            // to ensure "learningRateMultiplier" is required (not null)
            if (learningRateMultiplier == null)
            {
                throw new InvalidDataException("learningRateMultiplier is a required property for FineTuneHyperparams and cannot be null");
            }
            else
            {
                this.LearningRateMultiplier = learningRateMultiplier;
            }
            // to ensure "nEpochs" is required (not null)
            if (nEpochs == null)
            {
                throw new InvalidDataException("nEpochs is a required property for FineTuneHyperparams and cannot be null");
            }
            else
            {
                this.NEpochs = nEpochs;
            }
            // to ensure "promptLossWeight" is required (not null)
            if (promptLossWeight == null)
            {
                throw new InvalidDataException("promptLossWeight is a required property for FineTuneHyperparams and cannot be null");
            }
            else
            {
                this.PromptLossWeight = promptLossWeight;
            }
            this.ClassificationNClasses = classificationNClasses;
            this.ClassificationPositiveClass = classificationPositiveClass;
            this.ComputeClassificationMetrics = computeClassificationMetrics;
        }
        
        /// <summary>
        /// The batch size to use for training. The batch size is the number of training examples used to train a single forward and backward pass. 
        /// </summary>
        /// <value>The batch size to use for training. The batch size is the number of training examples used to train a single forward and backward pass. </value>
        [DataMember(Name="batch_size", EmitDefaultValue=false)]
        public int? BatchSize { get; set; }

        /// <summary>
        /// The number of classes to use for computing classification metrics. 
        /// </summary>
        /// <value>The number of classes to use for computing classification metrics. </value>
        [DataMember(Name="classification_n_classes", EmitDefaultValue=false)]
        public int? ClassificationNClasses { get; set; }

        /// <summary>
        /// The positive class to use for computing classification metrics. 
        /// </summary>
        /// <value>The positive class to use for computing classification metrics. </value>
        [DataMember(Name="classification_positive_class", EmitDefaultValue=false)]
        public string ClassificationPositiveClass { get; set; }

        /// <summary>
        /// The classification metrics to compute using the validation dataset at the end of every epoch. 
        /// </summary>
        /// <value>The classification metrics to compute using the validation dataset at the end of every epoch. </value>
        [DataMember(Name="compute_classification_metrics", EmitDefaultValue=false)]
        public bool? ComputeClassificationMetrics { get; set; }

        /// <summary>
        /// The learning rate multiplier to use for training. 
        /// </summary>
        /// <value>The learning rate multiplier to use for training. </value>
        [DataMember(Name="learning_rate_multiplier", EmitDefaultValue=false)]
        public decimal? LearningRateMultiplier { get; set; }

        /// <summary>
        /// The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset. 
        /// </summary>
        /// <value>The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset. </value>
        [DataMember(Name="n_epochs", EmitDefaultValue=false)]
        public int? NEpochs { get; set; }

        /// <summary>
        /// The weight to use for loss on the prompt tokens. 
        /// </summary>
        /// <value>The weight to use for loss on the prompt tokens. </value>
        [DataMember(Name="prompt_loss_weight", EmitDefaultValue=false)]
        public decimal? PromptLossWeight { get; set; }

        /// <summary>
        /// Returns the string presentation of the object
        /// </summary>
        /// <returns>String presentation of the object</returns>
        public override string ToString()
        {
            var sb = new StringBuilder();
            sb.Append("class FineTuneHyperparams {\n");
            sb.Append("  BatchSize: ").Append(BatchSize).Append("\n");
            sb.Append("  ClassificationNClasses: ").Append(ClassificationNClasses).Append("\n");
            sb.Append("  ClassificationPositiveClass: ").Append(ClassificationPositiveClass).Append("\n");
            sb.Append("  ComputeClassificationMetrics: ").Append(ComputeClassificationMetrics).Append("\n");
            sb.Append("  LearningRateMultiplier: ").Append(LearningRateMultiplier).Append("\n");
            sb.Append("  NEpochs: ").Append(NEpochs).Append("\n");
            sb.Append("  PromptLossWeight: ").Append(PromptLossWeight).Append("\n");
            sb.Append("}\n");
            return sb.ToString();
        }
  
        /// <summary>
        /// Returns the JSON string presentation of the object
        /// </summary>
        /// <returns>JSON string presentation of the object</returns>
        public virtual string ToJson()
        {
            return JsonConvert.SerializeObject(this, Formatting.Indented);
        }

        /// <summary>
        /// Returns true if objects are equal
        /// </summary>
        /// <param name="input">Object to be compared</param>
        /// <returns>Boolean</returns>
        public override bool Equals(object input)
        {
            return this.Equals(input as FineTuneHyperparams);
        }

        /// <summary>
        /// Returns true if FineTuneHyperparams instances are equal
        /// </summary>
        /// <param name="input">Instance of FineTuneHyperparams to be compared</param>
        /// <returns>Boolean</returns>
        public bool Equals(FineTuneHyperparams input)
        {
            if (input == null)
                return false;

            return 
                (
                    this.BatchSize == input.BatchSize ||
                    (this.BatchSize != null &&
                    this.BatchSize.Equals(input.BatchSize))
                ) && 
                (
                    this.ClassificationNClasses == input.ClassificationNClasses ||
                    (this.ClassificationNClasses != null &&
                    this.ClassificationNClasses.Equals(input.ClassificationNClasses))
                ) && 
                (
                    this.ClassificationPositiveClass == input.ClassificationPositiveClass ||
                    (this.ClassificationPositiveClass != null &&
                    this.ClassificationPositiveClass.Equals(input.ClassificationPositiveClass))
                ) && 
                (
                    this.ComputeClassificationMetrics == input.ComputeClassificationMetrics ||
                    (this.ComputeClassificationMetrics != null &&
                    this.ComputeClassificationMetrics.Equals(input.ComputeClassificationMetrics))
                ) && 
                (
                    this.LearningRateMultiplier == input.LearningRateMultiplier ||
                    (this.LearningRateMultiplier != null &&
                    this.LearningRateMultiplier.Equals(input.LearningRateMultiplier))
                ) && 
                (
                    this.NEpochs == input.NEpochs ||
                    (this.NEpochs != null &&
                    this.NEpochs.Equals(input.NEpochs))
                ) && 
                (
                    this.PromptLossWeight == input.PromptLossWeight ||
                    (this.PromptLossWeight != null &&
                    this.PromptLossWeight.Equals(input.PromptLossWeight))
                );
        }

        /// <summary>
        /// Gets the hash code
        /// </summary>
        /// <returns>Hash code</returns>
        public override int GetHashCode()
        {
            unchecked // Overflow is fine, just wrap
            {
                int hashCode = 41;
                if (this.BatchSize != null)
                    hashCode = hashCode * 59 + this.BatchSize.GetHashCode();
                if (this.ClassificationNClasses != null)
                    hashCode = hashCode * 59 + this.ClassificationNClasses.GetHashCode();
                if (this.ClassificationPositiveClass != null)
                    hashCode = hashCode * 59 + this.ClassificationPositiveClass.GetHashCode();
                if (this.ComputeClassificationMetrics != null)
                    hashCode = hashCode * 59 + this.ComputeClassificationMetrics.GetHashCode();
                if (this.LearningRateMultiplier != null)
                    hashCode = hashCode * 59 + this.LearningRateMultiplier.GetHashCode();
                if (this.NEpochs != null)
                    hashCode = hashCode * 59 + this.NEpochs.GetHashCode();
                if (this.PromptLossWeight != null)
                    hashCode = hashCode * 59 + this.PromptLossWeight.GetHashCode();
                return hashCode;
            }
        }

        /// <summary>
        /// To validate all properties of the instance
        /// </summary>
        /// <param name="validationContext">Validation context</param>
        /// <returns>Validation Result</returns>
        IEnumerable<System.ComponentModel.DataAnnotations.ValidationResult> IValidatableObject.Validate(ValidationContext validationContext)
        {
            yield break;
        }
    }
}
